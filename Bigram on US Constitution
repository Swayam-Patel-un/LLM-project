{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://github.com/Swayam-Patel-un/LLM-project/blob/main/The_US_Constitution.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-12T19:30:22.191569Z","iopub.execute_input":"2024-07-12T19:30:22.191930Z","iopub.status.idle":"2024-07-12T19:30:23.857347Z","shell.execute_reply.started":"2024-07-12T19:30:22.191903Z","shell.execute_reply":"2024-07-12T19:30:23.856471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\ndevice='cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T19:30:23.859424Z","iopub.execute_input":"2024-07-12T19:30:23.859744Z","iopub.status.idle":"2024-07-12T19:30:23.865487Z","shell.execute_reply.started":"2024-07-12T19:30:23.859716Z","shell.execute_reply":"2024-07-12T19:30:23.864524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"The_US_Constitution.txt\",\"r\",encoding=\"utf-8\") as f:\n    text=f.read()\n    \nprint(len(text))\nchar=sorted(set(text))\nprint(char)\nprint(len(char))\nvocab_size=len(char)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T19:30:23.866639Z","iopub.execute_input":"2024-07-12T19:30:23.866937Z","iopub.status.idle":"2024-07-12T19:30:23.890941Z","shell.execute_reply.started":"2024-07-12T19:30:23.866906Z","shell.execute_reply":"2024-07-12T19:30:23.890090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"str_to_int = { ch:i for i,ch in enumerate(char) }\nint_to_str = { i:ch for i,ch in enumerate(char) }\nencode = lambda s: [str_to_int[c] for c in s]\ndecode = lambda l: ''.join([int_to_str[i] for i in l])\n\nprint(encode('America'))\ndecode_am=decode(encode('America'))\nprint(decode_am)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T19:30:23.891988Z","iopub.execute_input":"2024-07-12T19:30:23.892276Z","iopub.status.idle":"2024-07-12T19:30:23.898718Z","shell.execute_reply.started":"2024-07-12T19:30:23.892248Z","shell.execute_reply":"2024-07-12T19:30:23.897878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=torch.tensor(encode(text), dtype=torch.long)\nprint(data[:100])","metadata":{"execution":{"iopub.status.busy":"2024-07-12T19:30:23.901462Z","iopub.execute_input":"2024-07-12T19:30:23.901881Z","iopub.status.idle":"2024-07-12T19:30:24.079767Z","shell.execute_reply.started":"2024-07-12T19:30:23.901850Z","shell.execute_reply":"2024-07-12T19:30:24.078849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=int(0.75*len(data))\ntrain=data[:n]\ntest=data[n:]\nblocksize=128\nbatchsize=32\neval_iter=150\ndropout=0.2\nx=train[:blocksize]\ny=train[1:blocksize+1]\n#for i in range(blocksize):\n#    cont=x[:i+1]\n#    tar=y[i]\n#    print(\"When input is \",cont,\" target is \",tar)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T19:30:24.080770Z","iopub.execute_input":"2024-07-12T19:30:24.081035Z","iopub.status.idle":"2024-07-12T19:30:24.086824Z","shell.execute_reply.started":"2024-07-12T19:30:24.081012Z","shell.execute_reply":"2024-07-12T19:30:24.085797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_batch(split):\n    data=train if split=='train' else test\n    ix=torch.randint(len(data)-blocksize,(batchsize,))\n    print(ix)\n    x=torch.stack([data[i:i+blocksize] for i in ix])\n    y=torch.stack([data[i+1:i+blocksize+1] for i in ix])\n    x=x.to(device)\n    y= y.to(device)\n    return x, y\n\nx,y=get_batch('train')\nprint(\"inputs:\")\nprint(x)\nprint(\"targets:\")\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T19:30:24.087798Z","iopub.execute_input":"2024-07-12T19:30:24.088054Z","iopub.status.idle":"2024-07-12T19:30:24.103737Z","shell.execute_reply.started":"2024-07-12T19:30:24.088032Z","shell.execute_reply":"2024-07-12T19:30:24.102964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iter)\n        for k in range(eval_iter):\n            X, Y = get_batch(split)\n            logit, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-07-12T19:30:24.104811Z","iopub.execute_input":"2024-07-12T19:30:24.105133Z","iopub.status.idle":"2024-07-12T19:30:24.111817Z","shell.execute_reply.started":"2024-07-12T19:30:24.105103Z","shell.execute_reply":"2024-07-12T19:30:24.110987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BigramLanguage(nn.Module):\n    def __init__(self, vocab_size):\n        super().__init__()\n        self.token_embedding_table=nn.Embedding(vocab_size,vocab_size)\n        \n    def forward(self, index, tar=None):\n        logits=self.token_embedding_table(index)\n        if tar is None:\n            loss=None\n        else:\n            b,t,c=logits.shape\n            logits=logits.view(b*t,c)\n            tar=tar.view(b*t)\n            loss=F.cross_entropy(logits, tar)\n        return logits,loss\n    \n    def generate(self, index, max_new_token):\n        for _ in range(max_new_token):\n            logits, loss = self.forward(index)\n            logits=logits[:,-1,:]\n            probs=F.softmax(logits,dim=-1)\n            indexnext=torch.multinomial(probs, num_samples=1)\n            index=torch.cat((index,indexnext),dim=-1)\n        return index\n    \nmodel=BigramLanguage(vocab_size)\nm=model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T19:30:24.112831Z","iopub.execute_input":"2024-07-12T19:30:24.113120Z","iopub.status.idle":"2024-07-12T19:30:24.123044Z","shell.execute_reply.started":"2024-07-12T19:30:24.113098Z","shell.execute_reply":"2024-07-12T19:30:24.122275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learnrate=3e-4\noptimizer=torch.optim.AdamW(model.parameters(), lr=learnrate)\neval_iters=50\nmax_iters=3000\nfor iter in range(max_iters):\n    if iter % eval_iters == 0:\n        losses = estimate_loss()\n        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n    xb, yb = get_batch('train')\n    logits, loss = model.forward(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\nprint(loss.item())","metadata":{"execution":{"iopub.status.busy":"2024-07-12T19:31:18.130377Z","iopub.execute_input":"2024-07-12T19:31:18.131230Z","iopub.status.idle":"2024-07-12T19:31:53.350724Z","shell.execute_reply.started":"2024-07-12T19:31:18.131183Z","shell.execute_reply":"2024-07-12T19:31:53.349818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context=torch.zeros((1,1), dtype=torch.long, device=device)\ngenerated_chars=decode(m.generate(context,max_new_token=500)[0].tolist())\nprint(generated_chars)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T19:37:32.127312Z","iopub.execute_input":"2024-07-12T19:37:32.127999Z","iopub.status.idle":"2024-07-12T19:37:32.421897Z","shell.execute_reply.started":"2024-07-12T19:37:32.127968Z","shell.execute_reply":"2024-07-12T19:37:32.420996Z"},"trusted":true},"execution_count":null,"outputs":[]}]}